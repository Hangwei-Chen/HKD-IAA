# HKD-IAA
This is the official code for the HKD-IAA (TMM2024).
## ğŸ”— Paper Link
- **Title**: Cross-Modal Hierarchical Knowledge Distillation for Image Aesthetics Assessment. [Link](https:)
![img](Method.png)

## ğŸ“ƒ Dependencies
- pytorch
- torchvision
- tqdm

## â¬ Download
- The pre-trained Multimodal teacher model: [Baidu Cloud](https:). (password: IAA6), or [Google Drive](https:)
- The AVA-Captions dataset Label (The User comments have been cleaned): [Baidu Cloud](https://pan.baidu.com/s/1xZ6qV-hMmsQqr9QL-dyrcg). (password: IAA6), or [Google Drive](https://drive.google.com/file/d/1btO_UHf2bbdTMtxpKKByicwq0TE14AyC/view?usp=sharing)
- The method we use to clean user comments can be found hereï¼š[Clean comments](https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019)

## ğŸ“‚ Dataset and comments
- You can download the AVA database at here: [AVA](https://github.com/imfing/ava_downloader)


## ğŸ“‰ Training
```
python main.py
```

## âœ¨ Statement
This project is for research purpose only, please contact us for the licence of commercial use. For any other questions please contact 1010075746@qq.com or shaofeng@nbu.edu.cn

## ğŸ” Citation
If our criteria are helpful, please consider citing the following papers.
```
@article{HKD-IAA,
  title={Cross-Modal Hierarchical Knowledge Distillation for Image Aesthetics Assessment},
  author={Hangwei Chen, Feng Shao, Weiyi Jing, Huizhi Wang, Qiuping Jinag},
  journal={Transactions on Multimedia},
  year={2024},
}
```



