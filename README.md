# HKD-IAA
This is the official code for the HKD-IAA (TMM2024).
## üîó Paper Link
- **Title**: Cross-Modal Hierarchical Knowledge Distillation for Image Aesthetics Assessment. [Link](https:)
![img](Method.png)

## üìÉ Dependencies
- pytorch
- torchvision
- tqdm

## ‚è¨ Download
- The pre-trained Multimodal teacher model: [Baidu Cloud](https://pan.baidu.com/s/1n3u3kwvj4s9NLeWLkD6nZA). (password: IAA6), or [Google Drive](https://drive.google.com/file/d/1i9OSUeMsXdzapnDY4aqpf7eX-lC3dk7_/view?usp=sharing)
- The AVA-Captions dataset Label (The User comments have been cleaned): [Baidu Cloud](https://pan.baidu.com/s/1xZ6qV-hMmsQqr9QL-dyrcg). (password: IAA6), or [Google Drive](https://drive.google.com/file/d/1btO_UHf2bbdTMtxpKKByicwq0TE14AyC/view?usp=sharing)
- The method we use to clean user comments can be found hereÔºö[Clean comments](https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019)

## üìÇ Dataset and comments
- You can download the AVA database at here: [AVA](https://github.com/imfing/ava_downloader)


## üìâ Training
```
python main.py
```

## ‚ú® Statement
This project is for research purpose only, please contact us for the licence of commercial use. For any other questions please contact 1010075746@qq.com or shaofeng@nbu.edu.cn

## üîç Citation
If our criteria are helpful, please consider citing the following papers.
```
@article{HKD-IAA,
  title={Cross-Modal Hierarchical Knowledge Distillation for Image Aesthetics Assessment},
  author={Hangwei Chen, Feng Shao, Weiyi Jing, Huizhi Wang, Qiuping Jinag},
  journal={Transactions on Multimedia},
  year={2024},
}
```



